20150311：

 增加支持长连接相关逻辑(避免端口耗尽的问题)
 
 服务端：socketlistener(支持配置supportkeepalive)
         如果supportKeepAlive为true:
         1、增加一个线程和一个字典，字典保存已建立连接的recsendsocket，即recsendsocket在非socketerror和transferbyte==0的情况下，一律不再主动关闭，而是放入了
		    字典中保存，并在相关usertoken中记录status为心跳保持连接状态并刷新相关serversession的时间。
		 2、同时起线程每10秒扫描该字典，对于超过一分钟没有复用的recsendsocke进行清理关闭操作。

 客户端：clientsocketprocessor(支持配置supportkeepalive)
        如果supportKeepAlive为true
	    1、实例化一个ConcurrentStack池：poolOfHeartBeatRecSend
		2、当SendMessage时，第一时间从poolOfHeartBeatRecSend提取一个已建立连接的SAEA，如果返回null，走并发连接控制等流程。
		   如果提取到SAEA，则用该SAEA发送到服务器。
		3、分别在ProcessSend和ProcessReceive，成功发送和接收后进行SetToHeartBeatStatus处理，即立刻将当前SAEA Push到poolOfHeartBeatRecSend，线程休眠10秒后
		   随机从poolOfHeartBeatRecSend提取SAEA发送心跳信息。
		   这里处理不对，还是另起一线程更好！否则影响所有的并发线程都休眠！！！

20150313：

服务端：仔细考虑，不需要额外的线程，只要不主动关闭socket即可，当客户端发送心跳信息，则会主动关闭，否则，要么继续接收信息要么等超时的socket error。
        这样，我们不再限制服务端的增长，只要内存够大(用于接收相关连接信息ip+port<这个port是远程的与本机无关！>,cpu足够快，那么可以无限接收连接!)
客户端：心跳信息则是用来关闭连接的，否则应用层协议需要长时间保持连接的话，再发送类似心跳的相关信息是合理做法。

昨天所谓耗尽port只存在于转发的代理服务器或者测试用的客户端，才存在，因为消耗的是本地的ip+port，对于远程没这个概念。

测试目前没问题，稳定在33个并发连接自动不再增长，处理了速度，每秒稳定在20000条，这是个基准。

20140331：

配置重要参数说明：
client:

   hostinfo
   connectsocket_count:这个数没所谓，实际上随着运行是可动态增长的。高了低了问题不大。
   datasocket_count:并发控制的就是这个数，注意调整(不同于服务端，其占用端口)，建议不超过1000，毕竟端口有限，还有其他服务要用的。
   buffersize：字节为单位，实际涉及分配为此数的2倍(一个接收，一个发送)，乘以datasocket_count为最终占用内存大小
   timeoutbyms(ms)
   keepalive：一般为true啦，复用很重要！
  
server:

   hostinfo
   connectsocket_count:这个数没所谓，实际上随着运行是可动态增长的。高了低了问题不大。
   datasocket_count:并发控制的就是这个数，注意调整，不同于客户端，服务端这个值可配置更大些，考虑内存足够(影响内存固定分配的大小，但不占端口)的话，越大越好！
   buffersize：字节为单位，实际涉及分配为此数的2倍(一个接收，一个发送)，乘以datasocket_count为最终占用内存大小
   keepalive：一般为true啦，复用很重要！


